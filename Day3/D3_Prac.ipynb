{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hmry1Zq7aZOO"
   },
   "source": [
    "# Earthquake location as an inverse problem\n",
    "\n",
    "[![Open In Colab](https://img.shields.io/badge/open%20in-Colab-b5e2fa?logo=googlecolab&style=flat-square&color=ffd670)](https://colab.research.google.com/github/tsonpham/ObsSeisHUS2025/blob/master/Day3/D3_Prac.ipynb)\n",
    "\n",
    "Prepared by Thanh-Son Pham (thanhson.pham@anu.edu.au), April 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWfAaJBcaZOR"
   },
   "source": [
    "---\n",
    "## What we do in this notebook\n",
    "\n",
    "Here we demonstrate a real inverse problem example of determining the earthquake hypocentre using  seismic data,\n",
    "- Cast the hypocentre determination for as an inverse problem\n",
    "- Solve the inverse problem in the optimal framework, by minimizing a misfit function\n",
    "- Solve the inverse problem in the Bayesian framework with the advanced ensemble samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3315,
     "status": "ok",
     "timestamp": 1745217986237,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "TQRJH86KaZOS",
    "outputId": "1f31a8dc-58b9-4b6d-9018-19ef25ec7a5b"
   },
   "outputs": [],
   "source": [
    "# Environemtal setup (uncomment if running in colab)\n",
    "\n",
    "# !pip install emcee obspy arviz numpy==1.26.4 basemap corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1745217986394,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "PrNIGHbaaZOT"
   },
   "outputs": [],
   "source": [
    "#@title Setting notebook resolution\n",
    "#@markdown Run this cell for better figure resolution\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams[\"savefig.dpi\"] = 100\n",
    "rcParams[\"figure.dpi\"] = 100\n",
    "rcParams[\"font.size\"] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr1yZv2DaZOT"
   },
   "source": [
    "---\n",
    "## Problem setup\n",
    "\n",
    "We download some waveform data from the IRIS server in preparation for the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 12523,
     "status": "ok",
     "timestamp": 1745217998919,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "AUb30dQfaZOU",
    "outputId": "c711d7d3-00c3-4ee5-a61d-420c1fe23c52"
   },
   "outputs": [],
   "source": [
    "#@title Run to download example seismic data\n",
    "#@markdown Let start with download some waveform data of the M5.2 Kon Tum 28/07/2024 earthquake to demonstrate the example. This cell downloads seismic data from the IRIS database using the `mass_downloader`. For more instruction, see Day2 self-practice [excercise](https://colab.research.google.com/github/tsonpham/ObsSeis-VNU/blob/master/Day2/D2_Prac.ipynb) to learn more.\n",
    "\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.clients.fdsn.mass_downloader import CircularDomain, Restrictions, MassDownloader\n",
    "\n",
    "# Initialize the client for ISC\n",
    "isc = Client(\"ISC\")\n",
    "# Request event information\n",
    "event = isc.get_events(eventid=\"641665444\")[0]\n",
    "origin_time = event.preferred_origin().time\n",
    "origin_lat = event.preferred_origin().latitude\n",
    "origin_lon = event.preferred_origin().longitude\n",
    "\n",
    "# Circular domain around the epicenter\n",
    "domain = CircularDomain(origin_lat, origin_lon, minradius=0.0, maxradius=15.0)\n",
    "# Restriction on the waveform data\n",
    "restrictions = Restrictions(\n",
    "    starttime=origin_time - 1 * 60,\n",
    "    endtime=origin_time + 10 * 60,\n",
    "    reject_channels_with_gaps=True,\n",
    "    minimum_length=0.95,\n",
    "    minimum_interstation_distance_in_m=150E3,\n",
    "    channel_priorities=[\"BH[ZNE12XY]\", \"HH[ZNE]\"],\n",
    "    location_priorities=[\"\", \"00\", \"10\"])\n",
    "\n",
    "# Initialize the mass downloader with specific providers\n",
    "mdl = MassDownloader(providers=['IRIS'])\n",
    "mdl.download(domain, restrictions, mseed_storage=\"waveforms\", stationxml_storage=\"stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1745217999462,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "5MliFIvCaZOV"
   },
   "outputs": [],
   "source": [
    "#@title Run to read waveform and metadata\n",
    "#@markdown This cell reads the downloaded data and creates an Inventory `inv` and Stream `dstream` objects for meta and waveform data.\n",
    "\n",
    "from obspy import read_inventory, read, Inventory, Stream\n",
    "from pathlib import Path\n",
    "## Read all the stationxml files and merge them into one Inventory object\n",
    "inv = Inventory()\n",
    "for file in Path(\"stations\").glob(\"*.xml\"): inv += read_inventory(str(file))\n",
    "## Read all the waveform files and merge them into one Stream object\n",
    "dstream = Stream()\n",
    "for file in Path(\"waveforms\").glob(\"*.mseed\"): dstream += read(str(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 9167,
     "status": "ok",
     "timestamp": 1745218008632,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "kFqWvriSaZOV",
    "outputId": "be69a570-23e9-4fe7-c8fd-70fdde96a799"
   },
   "outputs": [],
   "source": [
    "#@title Run to plot the station map\n",
    "#@markdown Let's plot the event location (available in the ISC bulletin, event id [641665444](https://isc.ac.uk/cgi-bin/web-db-run?event_id=641665444&out_format=ISF2&request=COMPREHENSIVE) and available seismic stations on the map. The `plot_map` funtion is defined to plot the event configuration at several occasions.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import numpy as np\n",
    "from obspy.geodetics import locations2degrees\n",
    "\n",
    "def plot_map(event, inv, obs_data=None, contour=False):\n",
    "    # create a new figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "    # initialize the basemap, specifing the projection, the gegraphic buondary, and resolution\n",
    "    # the initialzed map instance is attached to the axis\n",
    "    m = Basemap(projection='merc',ax=ax, llcrnrlat=0, urcrnrlat=26, llcrnrlon=94, urcrnrlon=122, resolution='l')\n",
    "    # draw coastlines\n",
    "    m.drawcoastlines(linewidth=0.75)\n",
    "    # draw country boundaries\n",
    "    m.drawcountries(linewidth=0.75)\n",
    "    # draw parallels and meridians\n",
    "    m.drawparallels(range(0, 25, 5), labels=[1,0,0,0], linewidth=0.3, color='gray', dashes=(5, 3))\n",
    "    m.drawmeridians(range(90, 125, 5), labels=[0,0,0,1], linewidth=0.3, color='gray', dashes=(5, 3))\n",
    "    # plot the epicenter\n",
    "    m.plot(event.preferred_origin().longitude, event.preferred_origin().latitude,\n",
    "           'rx', markersize=12, label='ISC location', latlon=True)\n",
    "    # plot the station locations\n",
    "    for network in inv:\n",
    "        for station in network:\n",
    "            lon = station.longitude\n",
    "            lat = station.latitude\n",
    "            # mark the station location\n",
    "            m.plot(lon, lat, '^', c='gray', markersize=4, latlon=True)\n",
    "            # put the station label\n",
    "            x, y = m(lon, lat)\n",
    "            ax.text(x, y+2.5e4, station.code, fontsize=8, color='gray', ha='center',\n",
    "                    bbox=dict(fc='white', ec='none', boxstyle='round,pad=0.0'))\n",
    "    # plot station in the observed data\n",
    "    if obs_data:\n",
    "        for k, v in obs_data.items():\n",
    "            # mark the station location\n",
    "            m.plot(v['lon'], v['lat'], '^', c='blue', markersize=4, latlon=True)\n",
    "            # put the station label\n",
    "            x, y = m(v['lon'], v['lat'])\n",
    "            ax.text(x, y+2.5e4, k, fontsize=8, color='blue', ha='center',\n",
    "                    bbox=dict(fc='white', ec='none', boxstyle='round,pad=0.0'))\n",
    "\n",
    "    if contour: # plot the distance contours to the epicenter\n",
    "        # plot distance contours to the epicenter\n",
    "        x = np.linspace(m.xmin, m.xmax, 300)\n",
    "        y = np.linspace(m.ymin, m.ymax, 300)\n",
    "        mlon, mlat = m(*np.meshgrid(x, y), inverse=True)\n",
    "        dist = locations2degrees(origin_lat, origin_lon, mlat, mlon)\n",
    "        c = m.contour(mlon, mlat, dist, levels=range(0, 19, 3), latlon=True, colors='k', linewidths=0.5)\n",
    "        plt.clabel(c, inline=1, fontsize=8, fmt='%dÂ°', colors='k')\n",
    "    # return the map instance\n",
    "    return m\n",
    "\n",
    "# plot the station map\n",
    "m = plot_map(event, inv, contour=True)\n",
    "m.ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4pUl8vDaZOW"
   },
   "source": [
    "---\n",
    "## Seismic observations: Differences of S- and P-wave arrivals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "227xX1e0aZOW"
   },
   "source": [
    "We reuse the measurements of P and S wave arrivals from Day 2 self-practice [excercise](https://isc.ac.uk/cgi-bin/web-db-run?event_id=641665444&out_format=ISF2&request=COMPREHENSIVE) encapsulated in a dictionary named `obs_data1`. Each dictionary entry corresponding to a station containting the station's coordinates, and P-, S-wave arrival times and their difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1745218008692,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "o929KY2JaZOW"
   },
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "\n",
    "# Picked P and S arrival times for stations QIZ, VIVO, and PBKT as done in the Day 2 practical notebook\n",
    "obs_data1 = {\n",
    "    'QIZ':  {'parv': UTCDateTime(2024,7,28,4,36,20), 'sarv': UTCDateTime(2024,7,28,4,37,9)},\n",
    "    'VIVO': {'parv': UTCDateTime(2024,7,28,4,36,37), 'sarv': UTCDateTime(2024,7,28,4,37,35)},\n",
    "    'PBKT': {'parv': UTCDateTime(2024,7,28,4,37,0), 'sarv': UTCDateTime(2024,7,28,4,38,20)}\n",
    "    }\n",
    "\n",
    "# update the station coordinates from the inventory\n",
    "for key, value in obs_data1.items():\n",
    "    tmp = inv.select(station=key)\n",
    "    obs_data1[key].update({'lat': tmp[0][0].latitude, 'lon': tmp[0][0].longitude,\n",
    "                           # S-P differential arrival time\n",
    "                           'tdiff': value['sarv'] - value['parv']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 14435,
     "status": "ok",
     "timestamp": 1745218023129,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "AIB6tu1aaZOW",
    "outputId": "3a1edaac-5566-478f-f9d8-21c88b1d7d2f"
   },
   "outputs": [],
   "source": [
    "#@title Click to visualze seismic observations\n",
    "#@markdown This cell plots data and their picked P- and S-wave arrivals for quality assurance.\n",
    "\n",
    "def plot_waveform(stacode, obs_data, filter_kw=dict(type='highpass', freq=0.1, corners=2, zerophase=False)):\n",
    "    # plot the waveform\n",
    "    st = dstream.select(station=stacode)\n",
    "    # rotate the 3 orthogonal component seismograms to vertical (Z), north (N), and east (E) directions\n",
    "    st.rotate('->ZNE', inventory=inv)\n",
    "    # view the first 5 minutes of the seismograms from the origin time\n",
    "    st.trim(origin_time, origin_time+300)\n",
    "    # sequence to detrend, taper, and filter the seismoograms\n",
    "    st.detrend('demean')\n",
    "    st.taper(max_percentage=0.05)\n",
    "    st.filter(**filter_kw)\n",
    "    # plot the seismograms\n",
    "    fig = plt.figure()\n",
    "    st.plot(fig=fig)\n",
    "    # mark the P and S arrival times\n",
    "    for ax in fig.axes:\n",
    "        # mark the P and S arrival times\n",
    "        ax.plot(obs_data[stacode]['parv'].datetime, 0, 'r|', markersize=20, label='P-arrival')\n",
    "        try:\n",
    "            ax.plot(obs_data[stacode]['sarv'].datetime, 0, 'b|', markersize=20, label='S-arrival')\n",
    "        except: # if the S-arrival is not provided\n",
    "            pass\n",
    "        # set the y-axis label\n",
    "        ax.set(ylabel='Amplitude', yticks=[0])\n",
    "\n",
    "    # show the figure legend\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "## plot the seismograms\n",
    "for key in obs_data1.keys():\n",
    "    plot_waveform(key, obs_data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMiVcqyFaZOX"
   },
   "source": [
    "### Definite the forward problem\n",
    "\n",
    "The forward problem inputs an event coordinate (lat and lon) to predict the S- to P-wave travel time difference to each station in the dataset, specifically,\n",
    "- input: hypocentral coordinates $(\\theta, \\phi)$\n",
    "- ouput: differential travel time of S- and P- wave arrivals\n",
    "\n",
    "The forward problem is hard to be expressed analytically. In seismology, it is common to use numerical solvers to define a forward problem.\n",
    "\n",
    "Here, we use the `taup` to predict travel times of seismic phases in spherial Earth models. The package was origninally written in the Java programming language, which is packaged in `obspy` to allow pythonic interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1745218023164,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "b5gP08cFaZOX"
   },
   "outputs": [],
   "source": [
    "from obspy.taup import TauPyModel\n",
    "taup_model = TauPyModel(model=\"ak135\")\n",
    "\n",
    "## calculate the theoretical P and S arrival times for the stations\n",
    "precomp_d = np.arange(0, 20.1, 0.5)\n",
    "precomp_tp = np.zeros_like(precomp_d)\n",
    "precomp_ts = np.zeros_like(precomp_d)\n",
    "for i, d in enumerate(precomp_d):\n",
    "    arrivals = taup_model.get_travel_times(0, d, ['P'])\n",
    "    precomp_tp[i] = arrivals[0].time\n",
    "    arrivals = taup_model.get_travel_times(0, d, ['S'])\n",
    "    precomp_ts[i] = arrivals[0].time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vm4HYzqQaZOX"
   },
   "source": [
    "For each hypocentral coordinate, the P and S travel time to each stations measured are computed using the taup `get_travel_times_geo` function. The prediction for each hypocentra will be S- to P- travel time differences corresponding to the observed stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1745218023448,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "UQ5b7uvzaZOX"
   },
   "outputs": [],
   "source": [
    "def forward_prob1(S):\n",
    "    '''\n",
    "    This forward problem returns the differential travel times of the S wave\n",
    "    and P wave for a given epicenter location S observed at three stations\n",
    "    QIZ, VIVO, PBKT.\n",
    "    '''\n",
    "    src_lat, src_lon = S\n",
    "    output = []\n",
    "    for rcv in obs_data1.values():\n",
    "        # distance from receiver to source\n",
    "        d = locations2degrees(src_lat, src_lon, rcv['lat'], rcv['lon'])\n",
    "        # calculate the theoretical P and S arrival times\n",
    "        t = np.interp(d, precomp_d, precomp_ts) - np.interp(d, precomp_d, precomp_tp)\n",
    "        output.append(t)\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lU3me6DDaZOX"
   },
   "source": [
    "### Optimal inverse solution\n",
    "\n",
    "First, we try to find the inverse solution by minizing the misfit function. Here we use the `Nelder-Mead` algoritm from a list of built-in [optimizers](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) from the `scipy` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1745218023636,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "-L6JeJ1UaZOX",
    "outputId": "6e4a91b0-9d23-4e7f-93f7-a0506556d79a"
   },
   "outputs": [],
   "source": [
    "## pre-defined optimizer\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "dt = np.array([v['tdiff'] for v in obs_data1.values()])\n",
    "## define the objective function\n",
    "def objective_function(S):\n",
    "    pred = forward_prob1(S)\n",
    "    return np.sum((dt - pred)**2)\n",
    "\n",
    "## optimize the objective function using the Nelder-Mead method\n",
    "S0 = (origin_lat, origin_lon)\n",
    "res = minimize(objective_function, x0=S0, method='Nelder-Mead')\n",
    "\n",
    "## print the result with defined format\n",
    "print (f'Optimized epicenter location: Latitude = {res.x[0]:.4f}, Longitude = {res.x[1]:.4f}')\n",
    "print (f'Success: {res.success}')\n",
    "print (f'Message: {res.message}')\n",
    "print (f'Number of function evaluations: {res.nfev}')\n",
    "print (f'Number of iterations: {res.nit}')\n",
    "print (f'Objective function value: {res.fun:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2ds5uEECjwB"
   },
   "source": [
    "The optimal solution looks reasonably good on a map. However, we know that the inverse solution is subjected to some uncertainty, how can we quantify it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 7118,
     "status": "ok",
     "timestamp": 1745218030755,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "S650NlZ3aZOY",
    "outputId": "c7bf70b0-e64b-44b3-9903-48e740b47d18"
   },
   "outputs": [],
   "source": [
    "m = plot_map(event, inv, obs_data1)\n",
    "m.plot(res.x[1], res.x[0], '+g', markersize=12, label='Optimized', latlon=True)\n",
    "m.ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vz_wRcrraZOY"
   },
   "source": [
    "### Bayesian sampling and ensemble solutions\n",
    "\n",
    "Now, we seek to find the ensemble of possible solution in form of the posterior distribution in the Bayesian approach.\n",
    "- The prior function defines a geographical box of earthquake lat, lon, where the proabiblity of event location is uniformly defined.\n",
    "- The likelihood assumes Gaussian data noise for three time difference measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 958,
     "status": "ok",
     "timestamp": 1745218031726,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "uFWIhQjuaZOY",
    "outputId": "35f504d6-302d-4efd-dbf4-978c13dd1a97"
   },
   "outputs": [],
   "source": [
    "lower_bound = (8, 94)\n",
    "upper_bound = (24, 118)\n",
    "\n",
    "def log_prior1(S):\n",
    "    '''\n",
    "    This function computes the prior probability of the epicenter location S.\n",
    "    '''\n",
    "    if not (lower_bound[0] <= S[0] <= upper_bound[0] and lower_bound[1] <= S[1] <= upper_bound[1]):\n",
    "        return -np.inf\n",
    "    return 0 # uninformative prior within the map boundary\n",
    "\n",
    "def log_likelihood1(S, sigma=5):\n",
    "    '''\n",
    "    This function computes the log likelihood of the observed data given the\n",
    "    epicenter location S.\n",
    "    '''\n",
    "    pred = forward_prob1(S)\n",
    "    sigma = np.ones_like(obs_data1) * sigma\n",
    "    return -.5 * np.sum((dt - pred)**2 / sigma**2 + np.log(2 * np.pi * sigma**2)) # Gaussian likelihood\n",
    "\n",
    "def log_prob1(X):\n",
    "    '''\n",
    "    This function computes the log likelihood of the observed data given an coordinate\n",
    "    in the parameter space.\n",
    "    '''\n",
    "    return log_prior1(X) + log_likelihood1(X, 10)\n",
    "\n",
    "## initialize the walkers\n",
    "nsteps = 400\n",
    "nwalkers = 32\n",
    "\n",
    "## number of dimensions, which is 2 for lat and lon of the epicenter\n",
    "ndim = 2\n",
    "walker_start = np.random.uniform(0, 1, (nwalkers, ndim))\n",
    "for i in range(ndim): # uniform start\n",
    "    walker_start[:, i] = walker_start[:, i] * (upper_bound[i] - lower_bound[i]) + lower_bound[i]\n",
    "\n",
    "## run the MCMC\n",
    "import emcee\n",
    "sampler1 = emcee.EnsembleSampler(nwalkers, ndim, log_prob_fn=log_prob1)\n",
    "output1 = sampler1.run_mcmc(walker_start, nsteps, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2--LvoaCjwC"
   },
   "source": [
    "The trace evolutions of invididual parameters look as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 19907,
     "status": "ok",
     "timestamp": 1745218051706,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "51H3vzXNaZOY",
    "outputId": "7e8ecadf-b7dd-4db1-a599-ae77f7036f07"
   },
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "idata1 = az.from_emcee(sampler1, var_names=['lat', 'lon'])\n",
    "ax = az.plot_trace(idata1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tquzavz2CjwC"
   },
   "source": [
    "The posterior confirm that the ISC location and the optimal solution (found above) are likely solutions. However, they also reveal other possible solutions up North (at the Vietnam-China boder). It is possibly due to the configuration of three observing stations. Do you have any thought on how to improve the configuration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 7855,
     "status": "ok",
     "timestamp": 1745218059565,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "QEb9L_OTaZOY",
    "outputId": "4695ea5f-12a5-45b7-e117-f321a19b6623"
   },
   "outputs": [],
   "source": [
    "x, y = m(idata1.posterior.lon.values, idata1.posterior.lat.values)\n",
    "m = plot_map(event, inv, obs_data1)\n",
    "az.plot_pair({'': x.flatten(), ' ': y.flatten()}, kind='kde', ax=m.ax,\n",
    "            kde_kwargs={'contour': False, 'pcolormesh_kwargs': {'cmap': 'BuGn'}})\n",
    "m.ax.set_title('Posterior distribution of epicenter location')\n",
    "m.ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEYB4uqgaZOY"
   },
   "source": [
    "### Hierachical Bayesian sampling\n",
    "\n",
    "Similar to the in-class exercise, we here employ the hierarchical approach to let the data decides their own noise level by introducing the hyperparameter, $\\sigma$, of noise level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1400,
     "status": "ok",
     "timestamp": 1745218060971,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "lMvNgk-waZOY",
    "outputId": "607b9e89-5ce4-4c3e-a995-460e6cc7beeb"
   },
   "outputs": [],
   "source": [
    "lower_bound = (8, 94, 0)\n",
    "upper_bound = (24, 118, 15)\n",
    "\n",
    "def log_prior1b(X):\n",
    "    '''\n",
    "    This function computes the prior probability of the epicenter location S.\n",
    "    '''\n",
    "    for i in range(len(X)):\n",
    "        if not (lower_bound[i] <= X[i] <= upper_bound[i]):\n",
    "            return -np.inf\n",
    "    return 0 # uninformative prior within the map boundary\n",
    "\n",
    "def log_likelihood1b(X):\n",
    "    '''\n",
    "    This function computes the log likelihood of the observed data given the\n",
    "    epicenter location S.\n",
    "    '''\n",
    "    pred = forward_prob1(X[:2])\n",
    "    sigma = np.ones_like(dt) * X[2]\n",
    "    return -.5 * np.sum((dt - pred)**2 / sigma**2 + np.log(2 * np.pi * sigma**2)) # Gaussian likelihood\n",
    "\n",
    "def log_prob1b(X):\n",
    "    '''\n",
    "    This function computes the log likelihood of the observed data given an coordinate\n",
    "    in the parameter space.\n",
    "    '''\n",
    "    return log_prior1b(X) + log_likelihood1b(X)\n",
    "\n",
    "## initialize the walkers\n",
    "nsteps = 1000\n",
    "nwalkers = 32\n",
    "\n",
    "## number of dimensions, which is 2 for lat and lon of the epicenter\n",
    "ndim = 3\n",
    "walker_start = np.random.uniform(0, 1, (nwalkers, ndim))\n",
    "for i in range(ndim): # uniform start\n",
    "    walker_start[:, i] = walker_start[:, i] * (upper_bound[i] - lower_bound[i]) + lower_bound[i]\n",
    "\n",
    "## run the MCMC\n",
    "sampler1b = emcee.EnsembleSampler(nwalkers, ndim, log_prob_fn=log_prob1b)\n",
    "output1b = sampler1b.run_mcmc(walker_start, nsteps, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 81399,
     "status": "ok",
     "timestamp": 1745218142371,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "2VJA1g-HaZOZ",
    "outputId": "5bf31404-d410-42c3-b835-a710b1cae6b7"
   },
   "outputs": [],
   "source": [
    "idata1b = az.from_emcee(sampler1b, var_names=['lat', 'lon', 'sigma'])\n",
    "ax = az.plot_trace(idata1b)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SXWzXwECjwD"
   },
   "source": [
    "The hypocentre location seem to converse well, but the hyperparameter, $\\sigma$, does not. This is because we only have three data point. It is hard to robustly separate 'signal' from 'noise' for such a small population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 15396,
     "status": "ok",
     "timestamp": 1745218157774,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "zViemZCsaZOZ",
    "outputId": "91360a16-ae60-43ec-c5fa-227f38eaebeb"
   },
   "outputs": [],
   "source": [
    "x, y = m(idata1b.posterior.lon.values, idata1b.posterior.lat.values)\n",
    "m = plot_map(event, inv, obs_data1)\n",
    "az.plot_pair({'': x.flatten(), ' ': y.flatten()}, kind='kde', ax=m.ax,\n",
    "            kde_kwargs={'contour': False, 'pcolormesh_kwargs': {'cmap': 'BuGn'}})\n",
    "m.ax.set_title('Posterior distribution of epicenter location')\n",
    "m.ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NBS0-HJaZOZ"
   },
   "source": [
    "---\n",
    "## Seismic observations: first P-wave arrivals\n",
    "\n",
    "You might have noticed that S-wave arrivals of this event are often noisy and hard to pick. Here we propose an alternative way to employ observation from more stations providing better azimuthal coverage to the source.\n",
    "\n",
    "P-wave arrivals are often easy to pick for more stations. However, one problem with P-wave arrivals only is that they are subjected to systematic errors due to the unknown event origin time. Our proposed solution is to use pairwise travel time differences. It minimizes the unceratinty assosiating to the unknown orign time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 120717,
     "status": "ok",
     "timestamp": 1745218278494,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "bOqWkVo7aZOZ",
    "outputId": "c21c102a-25af-4875-ac98-ccb7b1408039"
   },
   "outputs": [],
   "source": [
    "obs_data2 = {\n",
    "    'TWGB': {'parv': UTCDateTime(2024,7,28,4,38,40)},\n",
    "    'SBM': {'parv': UTCDateTime(2024,7,28,4,38,19)},\n",
    "    'KKM': {'parv': UTCDateTime(2024,7,28,4,38,3)},\n",
    "    'QIZ':  {'parv': UTCDateTime(2024,7,28,4,36,20)},\n",
    "    'VIVO': {'parv': UTCDateTime(2024,7,28,4,36,37)},\n",
    "    'PBKT': {'parv': UTCDateTime(2024,7,28,4,37,0)},\n",
    "    }\n",
    "\n",
    "# update the station coordinates from the inventory\n",
    "for key, rcv in obs_data2.items():\n",
    "    tmp = inv.select(station=key)\n",
    "    obs_data2[key].update({'lat': tmp[0][0].latitude, 'lon': tmp[0][0].longitude})\n",
    "\n",
    "## plot the seismograms\n",
    "for key in obs_data2.keys():\n",
    "    plot_waveform(key, obs_data2)#, filter_kw=dict(type='bandpass', freqmin=0.1, freqmax=1.0, corners=2, zerophase=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0I0vdKxMCjwD"
   },
   "source": [
    "Because the observed data have changed, we modify the forward problem predict the pair-wise travel time differences between observing stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1745218278885,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "kN8u4M5HaZOZ"
   },
   "outputs": [],
   "source": [
    "lower_bound = (8, 100, 0)\n",
    "upper_bound = (24, 115, 15)\n",
    "\n",
    "def forward_prob2(S):\n",
    "    '''\n",
    "    This forward problem returns the differential travel times of the S wave\n",
    "    and P wave for a given epicenter location S observed at three stations\n",
    "    QIZ, VIVO, PBKT.\n",
    "    '''\n",
    "    src_lat, src_lon = S[:2]\n",
    "    tp_pred = []\n",
    "    for rcv in obs_data2.values():\n",
    "        # distance from receiver to source\n",
    "        d = locations2degrees(src_lat, src_lon, rcv['lat'], rcv['lon'])\n",
    "        # calculate the theoretical P and S arrival times\n",
    "        tp_pred.append(np.interp(d, precomp_d, precomp_tp))\n",
    "    return  np.array(tp_pred)\n",
    "\n",
    "def log_likelihood2(X):\n",
    "    '''\n",
    "    This function computes the log likelihood of the observed data given the\n",
    "    epicenter location S.\n",
    "    '''\n",
    "    tp_pred = forward_prob2(X)\n",
    "    tp = np.array([v['parv'] for v in obs_data2.values()])\n",
    "\n",
    "    idx = np.triu_indices(len(tp_pred), 1)\n",
    "\n",
    "    tp_pred = tp_pred[idx[0]] - tp_pred[idx[1]]\n",
    "    # print ('pred', tp_pred.astype(int))\n",
    "    tp = tp[idx[0]] - tp[idx[1]]\n",
    "    # print ('obs', tp.astype(int))\n",
    "\n",
    "    sigma = X[2] * np.ones_like(tp_pred)\n",
    "    return -.5 * np.sum((tp - tp_pred)**2 / sigma**2 + np.log(2 * np.pi * sigma**2)) # Gaussian likelihood\n",
    "\n",
    "def log_prob2(X):\n",
    "    '''\n",
    "    This function computes the log likelihood of the observed data given an coordinate\n",
    "    in the parameter space.\n",
    "    '''\n",
    "    return log_prior1b(X) + log_likelihood2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 174771,
     "status": "ok",
     "timestamp": 1745218453659,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "zDvqBbmHaZOZ",
    "outputId": "9d45eaed-de36-4b87-d8e3-f7699b0abc4c"
   },
   "outputs": [],
   "source": [
    "## initialize the walkers\n",
    "nsteps = 5000\n",
    "nwalkers = 64\n",
    "\n",
    "## number of dimensions, which is 2 for lat and lon of the epicenter\n",
    "ndim = 3\n",
    "walker_start = np.random.uniform(0, 1, (nwalkers, ndim))\n",
    "for i in range(ndim): # uniform start\n",
    "    walker_start[:, i] = walker_start[:, i] * (upper_bound[i] - lower_bound[i]) + lower_bound[i]\n",
    "\n",
    "## run the MCMC\n",
    "sampler2 = emcee.EnsembleSampler(nwalkers, ndim, log_prob_fn=log_prob2)\n",
    "output2 = sampler2.run_mcmc(walker_start, nsteps, progress=True)\n",
    "\n",
    "## plot the sampling traces\n",
    "idata2 = az.from_emcee(sampler2, var_names=['lat', 'lon', 'sigma'])\n",
    "ax = az.plot_trace(idata2)\n",
    "plt.tight_layout()\n",
    "\n",
    "## source location distribution on map\n",
    "x, y = m(idata2.posterior.lon.values, idata2.posterior.lat.values)\n",
    "m = plot_map(event, inv, obs_data2)\n",
    "az.plot_pair({'': x.flatten(), ' ': y.flatten()}, kind='kde', ax=m.ax, kde_kwargs={\n",
    "            'contour': False, 'pcolormesh_kwargs': {'cmap': 'BuGn'}})\n",
    "m.ax.set_title('Posterior distribution of epicenter location')\n",
    "m.ax.legend(loc='upper right')\n",
    "m.plot(event.preferred_origin().longitude, event.preferred_origin().latitude,\n",
    "       'rx', markersize=12, label='Catalog', latlon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 698
    },
    "executionInfo": {
     "elapsed": 7170,
     "status": "ok",
     "timestamp": 1745218460835,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "S9D-V50yCjwE",
    "outputId": "8abb18a7-4a4d-41b7-b43b-3604e5ecb305"
   },
   "outputs": [],
   "source": [
    "######## autocorrelation time\n",
    "tau2 = sampler2.get_autocorr_time()\n",
    "print(f\"autocorrelation time: {tau2}\")\n",
    "\n",
    "######## corner plot to show pair-marginalized posterior distributions\n",
    "import corner\n",
    "flat_samples = sampler2.get_chain(discard=int(tau2.max()), thin=int(tau2.max()*.5), flat=True)\n",
    "fig = corner.corner(flat_samples, #labels=labels, #truths=list(true_model) + [sigma],\n",
    "                        quantiles=[0.025, 0.5, 0.975], show_titles=True,\n",
    "                        levels=(0.68, 0.95), alpha=0.1)\n",
    "fig.set_size_inches(7, 7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdIaeZTUCjwE"
   },
   "source": [
    "---\n",
    "## Challenge\n",
    "\n",
    "Currently we have picked P-wave arrivals for six stations recording the M5.2 Kon Tum 28/07/2024 earthquake. Would you try to pick the arrival time for a couple more stations and re-run the inversion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QO3kdruBaZOa"
   },
   "source": [
    "---\n",
    "## Remarks\n",
    "\n",
    "- Earthquake location is a classical inverse problem in seismology. We have worked with arrival time and casted our forward problem on ray theory for travel time predictions. There's a class of algorithm employing full waveform for earthquake location.\n",
    "\n",
    "- Dealing with real data requires flexibility and creation to over come limitation posed by the available data."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "emcee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
