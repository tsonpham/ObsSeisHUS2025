{"cells":[{"cell_type":"markdown","metadata":{"id":"0WOzInIgwSsx","vscode":{"languageId":"plaintext"}},"source":["# Automatic PKIKP Onset Phase Picker\n","\n","[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tsonpham/ObsSeisHUS2025/blob/master/Day5/D5_Lab.ipynb)\n","\n","Prepared by Thanh-Son Pham (thanhson.pham@anu.edu.au), April, 2025.\n","\n","This notebook demonstrates an application of convolutional neural network in deep Earth seismology. Here the AI tool automatises the laborious data collection process previously performed by skillful analysts. The train CNN network is trained on synthetic waveforms to pick the onset of PKIKP waves, the compressional waves transversing the whole Earth diameter, including the Earth's inner core. We expect that the ever-expanded dataset havested by AI could help reveal new insights into the structures and dynamics of the Earth's inner core.\n","\n","This notebook is adopted from the orignal [Github Repository](https://github.com/JiarunZhou/PKIKP_Onset_Picker.git) developed by PhD Scholar Jiarun Zhou (ANU) supplementing the following application:\n","\n","* Zhou J., T.-S. Phạm, H. Tkalčić, Deep-learning phase-onset picker for deep Earth seismology: PKIKP waves, Journal of Geophysical Research: Solid Earth, 129 (9), [10.1029/2024JB029360](https://doi.org/10.1029/2024JB029360), 2024."]},{"cell_type":"markdown","metadata":{"id":"U9fC9Fl4ipsu"},"source":["---\n","## What we do in this notebook\n","\n","- Get familiarised with `tensorflow` deep learning framework\n","- Train a convolutional neural network on synthetic training datasets\n","- Test the trained picker on real waveforms using the sliding window strategy"]},{"cell_type":"markdown","metadata":{"id":"vDva6xW29u3B"},"source":["### *IMPORTANT* Preparing the working environment\n","\n","Deep learning model traininging might be computationally expensive. Using GPU significantly reduce the compute time. In Google Colab, you have free access to GPU and TPU devices. It is strongly recommended to train the model using a GPU device. Select `Runtime`, `Change runtime type`, pick your device.\n","\n","After that, similar to other excercises, run the next cell to install Python packages in the working environments of the Colab session. Note that, the packages are removed from the evironment when this session is closed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zGTegE45zm69"},"outputs":[],"source":["# set up colab environment - uncomment the next line if running in colab\n","\n","!pip install obspy numpy==1.26.4"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"e7KsM8cspbs-"},"outputs":[],"source":["#@title Run to activate retina display\n","\n","%config InlineBackend.figure_format = \"retina\"\n","from matplotlib import rcParams\n","\n","rcParams[\"savefig.dpi\"] = 100\n","rcParams[\"figure.dpi\"] = 100\n","rcParams[\"font.size\"] = 10"]},{"cell_type":"markdown","metadata":{"id":"RvarmQHvwSs1"},"source":["---\n","## Training the convolutional neural network for PKIKP onset picker"]},{"cell_type":"markdown","metadata":{"id":"tGNODDXvwSs3"},"source":["#### Download training datasets\n","\n","We download the training datasets consisting of synthetic waveforms and labels. The datasets include three subsets: regular (synthetic P waves), target (particular emergent P waves), and control set (real noise). The waveforms are sampled at 40 Hz and generated to 20-s long. Non-zero labels mark the PKIKP wave onset, while zero labels indicate noisy waveforms. The datasets were simulated to mimic main features of teleseismic PKIKP waves transversing the Earth's inner core. More details can be found in Zhou et al. (2024)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iN6G7IZy5DGj"},"outputs":[],"source":["# download data from google drive using gdown\n","import gdown, zipfile\n","from pathlib import Path\n","## Download the Bedmap2 datasets in GeoTIFF format from Google Drive using gdown\n","url = \"https://drive.google.com/uc?id=14VV1W1mK3gIAWX4J8FWXtUilrLZnMtmE\"\n","if not Path('Data_pack.zip').exists():\n","    gdown.download(url, 'Data_pack.zip', quiet=False)\n","## Unzip the downloaded file\n","if not (Path('Train_data').exists() or Path('Test_data').exists()):\n","    with zipfile.ZipFile('Data_pack.zip', 'r') as f:\n","        f.extractall('.')"]},{"cell_type":"markdown","metadata":{"id":"dUwd0Hfk7dib"},"source":["The three files downloaded are 301M:\n","    \n","    301M\tNoise.hdf5\n","    301M\tRegularP.hdf5\n","    301M\tTargetP.hdf5\n","\n","Each contains 100,000 waveforms of 20 seconds long sampled at 40 samples per second.\n","\n","Next, the datasets are loaded into memory as `np.array`."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2025-03-12T02:17:59.623818Z","start_time":"2025-03-12T02:17:59.210700Z"},"id":"Fij1O1WIwSs4"},"outputs":[],"source":["from pathlib import Path\n","import h5py\n","import numpy as np\n","\n","## basic parameters\n","sampling_rate = 40\n","waveform_len = 20\n","\n","def load_train_data(loading_num):\n","    ## Load waveforms and onset labels.\n","    waveforms = [] # waveforms\n","    labels = [] # onset labels\n","    names = [] # sub dataset names\n","    for file in Path('Train_data').glob('*.hdf5'):\n","        with h5py.File(file, \"r\") as f: # open hdf5 and read content\n","            data = np.array(f[\"data\"])[:loading_num]\n","            t0 = np.array(f[\"t0\"])[:loading_num]\n","        waveforms.append(data)\n","        labels.append(t0)\n","        names.append(file.name.split('.')[0])\n","    print ('Datasets:', names)\n","    print (\"Total number of samples: %d\"%sum([len(_) for _ in waveforms]))\n","    return waveforms, labels, names\n","\n","waveforms, labels, names = load_train_data(loading_num=10000)"]},{"cell_type":"markdown","metadata":{"id":"YTLEQq4u_H4C"},"source":["The total available number of samples, i.e., pairs of waveform and onset label, are 295,275. However to reduce the actual training runtime for demonstration purposes, only 30,000 samples are loaded.\n","\n","30 samples randomly are picked from the datasets for visual inspection."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2025-03-12T02:17:59.741210Z","start_time":"2025-03-12T02:17:59.624601Z"},"id":"gLrvmkB5wSs6"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","tvec = np.arange(sampling_rate*waveform_len) / sampling_rate\n","fig, ax = plt.subplots(1, 3, sharex=True, sharey=True)\n","for i in range(3):\n","    tmp = np.random.randint(0, len(waveforms[i]), 10) # pick 10 random waveforms from the i-th subset\n","    for j in range(len(tmp)):\n","        # plot waveforms\n","        ax[i].plot(tvec, waveforms[i][tmp[j]] + j, c='k', lw=0.75)\n","        # plot labels\n","        ax[i].plot(labels[i][tmp[j]], j, '|r', ms=20, lw=1.5)\n","    ax[i].set(xlabel='Time [s]', title=names[i])\n","ax[0].set(ylabel='Sample index', ylim=(-1, 10))\n","fig.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"av3QCqTAwSs6"},"source":["### Model\n","Now, we build a neural network, whose architecture is visualized below, using tensorflow keras modules. The CNN model comprises of four 1D convolutional layers, followed by max pooling layers to downsize by half. The output of the convolutional layer is then flattened and fed into two fully connected layer, and finally outputed with linear operator.\n","\n","<div>\n","<center>\n","<img src=\"https://agupubs.onlinelibrary.wiley.com/cms/asset/952cff41-9b65-4343-8cd8-678090e9f543/jgrb56919-fig-0004-m.jpg\" width=\"300\"/>\n","</div>\n","(Source: https://doi.org/10.1029/2024JB029360)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2025-03-12T02:17:59.923213Z","start_time":"2025-03-12T02:17:59.748994Z"},"id":"qyksUZIjwSs7","scrolled":true},"outputs":[],"source":["## import necessary tensorflow keras modules\n","from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, BatchNormalization, Dense, Flatten\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.losses import Huber, Reduction\n","from tensorflow.keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping\n","\n","def create_CNN_picker(npts, normalize = True, lr = 0.001):\n","    ## define convolutional neural layers\n","    n_filters = [32, 64, 128, 256]\n","    s_kernels = [7, 5, 4, 3]\n","    inputs = Input(shape=(npts,1))\n","    x = inputs\n","    for n_filter, s_kernel in zip(n_filters, s_kernels):\n","        x = Conv1D(filters = n_filter, kernel_size = s_kernel, padding = 'same', activation = \"relu\")(x)\n","        x = MaxPooling1D()(x)\n","        if normalize:\n","            x = BatchNormalization()(x)\n","\n","    ## flatten the output of the convolutional layers\n","    x = Flatten()(x)\n","\n","    ## define fully connected, i.e., dense, layers\n","    for _ in range(2):\n","        x = Dense(200, activation = 'relu')(x)\n","        if normalize:\n","            x = BatchNormalization()(x)\n","\n","    ## output of the dense layer\n","    outputs = Dense(1, activation = \"linear\")(x)\n","\n","    ## define the CNN model and specify loss function and optimizer\n","    model = Model(inputs = inputs, outputs = outputs)\n","    model.compile(loss=Huber(reduction = Reduction.SUM_OVER_BATCH_SIZE),\n","                  optimizer=Adam(learning_rate = lr))\n","\n","    return model\n","\n","## call the definition function to instatitate the CNN model\n","model_raw = create_CNN_picker(npts = waveform_len*sampling_rate)\n","\n","## print model sumary\n","model_raw.summary()"]},{"cell_type":"markdown","metadata":{"id":"GNzvo2NxwSs7"},"source":["The expected summary model output reads\n","```\n"," Total params: 2,746,137 (10.48 MB)\n"," Trainable params: 2,744,377 (10.47 MB)\n"," Non-trainable params: 1,760 (6.88 KB)\n","```\n","The number of trainable params, 2,744,377, is the number of parameter that is to be estimated to minimize the `Huber` loss function between waveforms and labels. The loss funciton is minimized using the `Adam` optimizer. The optimization algorithm interatively finds a lower loss value when decending along the direction opposite to the loss function's gradient, i.e., gradient decent.\n","\n","Train the model and plot the curves of loss during the training process. An early stopping method that allows training stops early if the validation loss has no longer decreased over 5 epochs is used."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2025-03-12T03:38:03.714186Z","start_time":"2025-03-12T02:17:59.924063Z"},"id":"KUToW_twwSs8"},"outputs":[],"source":["from time import time\n","from obspy.core import UTCDateTime\n","\n","def trainer(x, y, model,\n","            epochs = 20,\n","            validation_split = 0.2,\n","            batch_size = 32,\n","            early_stop = True,\n","            verbose_training = 1,\n","            shuffle = True,\n","            plot_hist = True, save_plot = \"Loss_curve.jpg\"):\n","\n","    callbacks = []\n","    if early_stop == True:\n","        callbacks.append(\n","        EarlyStopping(monitor = 'val_loss',\n","                    start_from_epoch = 10,\n","                    patience = 5,\n","                    restore_best_weights = True,\n","                    verbose = 1)\n","        )\n","\n","    start_training_time = time()\n","    hist = model.fit(x, y,\n","                    epochs = epochs,\n","                    validation_split = validation_split,\n","                    batch_size = batch_size,\n","                    shuffle = shuffle,\n","                    callbacks = callbacks,\n","                    verbose = verbose_training)\n","    performance_time = time() - start_training_time\n","\n","    print(\"Training starts at\",UTCDateTime(start_training_time),\"; run in:\", performance_time)\n","    if plot_hist == True: plot_hist_curve(hist, save_plot)\n","\n","    return hist\n","\n","def plot_hist_curve(hist, save_plot):\n","    train_loss = hist.history[\"loss\"]\n","    val_loss = hist.history[\"val_loss\"]\n","    plt.figure()\n","    plt.plot(range(len(train_loss)),train_loss, label = \"Training_loss\")\n","    plt.plot(range(len(val_loss)),val_loss, label = \"Validation_loss\")\n","    plt.xlabel(\"Epoch\")\n","    plt.legend()\n","    if save_plot != False:\n","        plt.savefig(save_plot, dpi = 300)\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"JoYQ5J4aVXCh"},"source":["Three sets are split:\n","\n","- Training: The model learns from it;\n","- Validation: The model evaluates the loss on it after each epoch, and then updates weights itself by back propagation;\n","- Test: The trained model evaluates its final loss&accuracy.\n","\n","An early stopping method that allows training stops early if the validation loss has no longer decreased over 5 epochs is used. A warm-up period of 10 epochs is set for early stopping."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W3MWw1KpUlVX"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","## Stack three training sets\n","x = np.vstack(waveforms)\n","y = np.vstack(labels)\n","\n","## data is shuffled before splitting\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, shuffle = True, random_state = 101)\n","\n","## Train\n","hist = trainer(x_train, y_train,\n","        model_raw,\n","        epochs = 30,\n","        validation_split = 0.2,\n","        batch_size = 32,\n","        early_stop = True,\n","        verbose_training = 1,\n","        shuffle = True, # Shuffle the training data before each epoch\n","        plot_hist = True, save_plot = \"Loss_curve.jpg\")"]},{"cell_type":"markdown","metadata":{"id":"eTF-hChmPsFx"},"source":["The training process should take about 3 minutes when running with a T4 GPU device. The output figure shows the training and validation loss. The training loss (blue line) is minimized during the training process. Trained model can be used to predict the outputs corresponding to the test set, `x_test`, which has not been seen by the optimizer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xv8PWuj0van7"},"outputs":[],"source":["y_out = model_raw.predict(x_test)\n","\n","fig, ax = plt.subplots()\n","ax.set_aspect('equal')\n","ax.scatter(y_test, y_out)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"pyatJK1YwSs8"},"source":["---\n","## Testing the algorithm with real data"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"qjOaRgagRSko"},"outputs":[],"source":["#@title Supporting functions\n","#@markdown **Note**: The following functions are used to process the data and perform the picking. You can skip this section if you are only interested in the model training.\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import normalize\n","from sklearn.cluster import DBSCAN\n","\n","\n","def pre_process(data, sampling_rate = 40, len_input = 50,\n","                freq_min = 0.5, freq_max= 2, prediction = 60, detrend = True):\n","\n","    # Pre-process\n","    data.resample(sampling_rate)\n","    if detrend == True: data.detrend(type=\"linear\")\n","    data.filter(type=\"bandpass\", freqmin=freq_min, freqmax=freq_max)\n","\n","    #Cut\n","    st = []\n","    window_start = int(prediction-len_input*0.5)\n","    if window_start < 0:\n","        raise ValueError(\"The input waveform is too short (Default: 150 s) or the cut window is too long (Default: 50 s).\")\n","    for tr in data:\n","        tr = tr[window_start*sampling_rate:(window_start+len_input)*sampling_rate]\n","        tr = tr/np.max(abs(tr))\n","        st.append(tr)\n","\n","    return np.array(st)\n","\n","\n","def sliding_window_picking(tr, model, sampling_rate = 40, len_window = 20, t_shift = 0.1, only_valid = True):\n","    n_shift = t_shift * sampling_rate\n","    n_length = len_window*sampling_rate\n","\n","    tt = (np.arange(0, len(tr), n_shift)) /sampling_rate # start of each window\n","\n","    shape = [int(np.floor(len(tr)/n_shift - n_length/n_shift + 1)),n_length]\n","    strides = [int(tr.strides[0]*n_shift),tr.strides[0]]\n","    tr_win = np.lib.stride_tricks.as_strided(tr, shape=shape, strides=strides)\n","\n","    tr_win = normalize(tr_win,norm = \"max\")\n","    tt = tt[:len(tr_win)]\n","    tr_win = np.reshape(tr_win,(len(tr_win),len_window*sampling_rate,1))\n","    ts = model.predict(tr_win, verbose = False, batch_size=32) # pick in each window\n","\n","    if only_valid == True:\n","        # Only keep the picks in range of picking windows\n","        ts_valid = []\n","        for j in range(len(ts)):\n","            if np.abs(ts[j]) <= len_window and np.abs(ts[j]) >= 0:\n","                ts_valid.append(ts[j]+tt[j])\n","            else:\n","                ts_valid.append([0]) # Out-of-range picks will be reset to the end\n","        return tt, ts_valid\n","    else:\n","        return tt,ts\n","\n","\n","def cluster_preds(predictions, eps=0.1, min_neighbors=5):\n","    dbscan = DBSCAN(eps, min_samples=min_neighbors) ## Perform DBSCAN cluster\n","    dbscan.fit(predictions.reshape(-1,1))\n","    clusters, counts = np.unique(dbscan.labels_, return_counts=True)\n","    dbscan_labels = dbscan.labels_\n","    if -1 in clusters:\n","        clusters = clusters[1:]\n","        counts = counts[1:]\n","    picks = np.zeros(len(clusters))\n","    for c in clusters:\n","        picks[c] = np.mean(predictions[dbscan.labels_ == c])\n","\n","    if len(picks) == 0:\n","        picks == np.zeros(1)\n","        counts == np.zeros(1)\n","\n","    return picks, dbscan_labels, counts\n","\n","\n","def picker(data, model, sampling_rate = 40, t_shift = 0.1, eps = 0.1, return_optimal = True):\n","    len_window = 20 # model input length = sliding window length\n","\n","    picks_highest_quality = []\n","    qualities_highest = []\n","    picks_all = []\n","    qualities_all = []\n","\n","    if type(model) == str:\n","        model = load_model(model)\n","\n","    for tr in data:\n","        # Predict\n","        tt, ts_valid = sliding_window_picking(tr, model,\n","                                              sampling_rate, len_window, t_shift, only_valid = True)\n","\n","        # Cluster picks\n","        picks,dbscan_labels,counts = cluster_preds(np.array(ts_valid), eps=eps, min_neighbors=5)\n","        if len(picks) == 0:\n","            raise ValueError(\"No auto pick is returned.\")\n","\n","        # Quality of picks\n","        qualities = counts/(len_window/t_shift)\n","\n","        picks_highest_quality.append(picks[np.argmax(qualities)])\n","        qualities_highest.append(np.max(qualities))\n","        picks_all.append(picks)\n","        qualities_all.append(qualities)\n","\n","    if return_optimal == True:\n","        return picks_highest_quality, qualities_highest\n","    else:\n","        return picks_all, qualities_all\n","\n","\n","def auto_pick_plot(tr, model, save_name = \"Plot.jpg\"):\n","\n","    auto_picks, qualities = picker(tr, model, return_optimal = False)\n","    optimal_pick = auto_picks[0][np.argmax(qualities)]\n","\n","    fig = plt.figure(figsize=(7, 6))\n","    gs = fig.add_gridspec(2, 1,height_ratios=(3, 2),hspace=0.1)\n","    ax0 = fig.add_subplot(gs[0])\n","    ax0.plot(tr[0],c = \"k\",lw = 1.2)\n","    ax0.axvline(optimal_pick*40,c= \"g\",lw = 1.5,label = \"Automatic pick: %.2f s\"%optimal_pick)\n","    # ax0.axvline(onset_in_window*40,c = \"r\",lw = 1.5,label = \"Manual pick: %.2f s\"%onset_in_window)\n","    ax0.set_xticks(ticks = np.arange(0,2001,200), labels = [])\n","    ax0.set_yticks([-1,0,1])\n","    ax0.set_yticklabels([-1,0,1],fontsize = 14)\n","    ax0.set_ylabel(\"Amplitude\",fontsize = 15)\n","    ax0.set(xlim=(0,2000))\n","    ax0.legend(fontsize = 13,loc = \"upper left\")\n","\n","    ax1 = fig.add_subplot(gs[1])\n","    ax1.axvline(optimal_pick*40,c= \"g\",lw = 1.5,ls = \"dotted\")\n","    for ia,a in enumerate(auto_picks[0]):\n","        l1 = ax1.axvline(a*40,ymin = 0,ymax = qualities[0][ia],color = \"green\",lw  = 1.5)\n","    ax1.grid(True, axis = \"both\",linestyle = \"--\")\n","    ax1.set_xticks(np.arange(0,2001,200))\n","    ax1.set_xticklabels(np.arange(-25,26,5),fontsize = 14)\n","    ax1.set_xlabel(\"Time w.r.t. ak135 prediction (s)\",fontsize = 15)\n","    ax1.set_ylabel(\"Quality\",fontsize = 15)\n","    ax1.legend([l1],[\"Sliding-window \\npicks\"],fontsize = 13,loc = \"upper right\")\n","    plt.savefig(save_name,dpi=300,bbox_inches = \"tight\")\n","\n","\n","def picking_animation(tr, model, len_input = 50, sampling_rate = 40, t_shift = 0.1, save_name = \"Animation.mp4\"):\n","    from matplotlib.animation import FuncAnimation,FFMpegWriter\n","\n","    len_window = 20\n","\n","    ## Get instantaneous picks\n","    tt, ts = sliding_window_picking(tr[0], model, only_valid = False)\n","    ts = [ts[j] + tt[j] for j in range(len(ts))]\n","    picks,dbscan_labels,counts = cluster_preds(np.array(ts))\n","\n","    ## plot\n","    fig,ax = plt.subplots(2,figsize = (10,8),sharex = True)\n","    ax[0].set_ylim(-1.05,1.05)\n","    ax[0].plot(np.arange(0,len_input,1/sampling_rate),tr[0])\n","    # ax[0].axvline(onset_in_window, c= \"r\",lw = 2, ls = \"--\", label = \"Human picked arrival\")\n","    ln1, = ax[0].plot([],[], c= \"g\",lw = 2, label = \"Instantaneous CNN pick\")\n","    ln2, = ax[0].plot([], [], 'tab:grey',label = \"Sliding window\")\n","    ln3, = ax[0].plot([], [], 'tab:grey')\n","    ax[0].legend(loc = \"upper right\")\n","    ax[1].set_ylim(0,1)\n","    ax[1].set_xlabel(\"Time (s)\",fontsize = 15)\n","    ax[1].set_ylabel(\"Quality\",fontsize = 15)\n","    ax[1].set_xticks(np.arange(0,51,5))\n","    ln4, = ax[1].plot([],[],\"go\",ms=1.5)\n","    collection = ax[0].fill_between([0,len_window],-1.05,1.05,facecolor = \"lightgrey\",alpha = 0.5)\n","    xdata3,ydata3 = [],[]\n","    def update(frame):\n","        xdata = ts[frame]\n","        ydata = np.linspace(-1.05,1.05,100)\n","        xdata2 = tt[frame]\n","        xdata3.append(picks[dbscan_labels[frame]])\n","        dbscan_label_f = len([d for d in dbscan_labels[0:frame+1] if d == dbscan_labels[frame]])\n","\n","        if picks[dbscan_labels[frame]] != 0 and dbscan_labels[frame] != -1:\n","            try:\n","                len_ydata3 = dbscan_label_f/(len_window/t_shift)\n","            except ZeroDivisionError:\n","                len_ydata3 = 0\n","        else:\n","            len_ydata3 = 0\n","        ydata3.append(len_ydata3)\n","\n","        dummy = ax[0].fill_between([xdata2,xdata2+len_window], -1.05, 1.05, alpha=0)\n","        dp = dummy.get_paths()[0]\n","        dummy.remove()\n","        #update the vertices of the PolyCollection\n","        collection.set_paths([dp.vertices])\n","\n","        ln1.set_data(xdata,ydata)\n","        ln2.set_data([xdata2],ydata)\n","        ln3.set_data([xdata2+len_window],ydata)\n","        ln4.set_data(xdata3,ydata3)\n","\n","        return ln1,ln2,ln3,ln4\n","\n","    ani = FuncAnimation(fig, func = update, frames=len(ts), blit=True, repeat = False)\n","    writer = FFMpegWriter(fps = 15)\n","    ani.save(save_name,writer = writer,dpi = 300)"]},{"cell_type":"markdown","metadata":{"id":"u811OoFOwSs8"},"source":["Here we load the trained model."]},{"cell_type":"markdown","metadata":{"id":"7fUui8dNwSs9"},"source":["Read an observed real PKIKP waveform example. Here, the waveform has 150-s length. The predicted PKIKP onset by ak135 model (Kennett et al., 1995) is located at the 60th second. Hand-picked PKIKP absolute travel time is provided in its information."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2025-03-12T03:42:44.242014Z","start_time":"2025-03-12T03:42:44.214809Z"},"id":"54B0RdmNwSs9"},"outputs":[],"source":["from obspy import read, Stream\n","\n","tr = read(\"Test_data/PKP_NE22.YP.BHZ.SAC\")\n","PKIKP_travel_time = tr[0].stats.sac.t2\n","waveform_start = tr[0].stats.sac.b\n","onset = PKIKP_travel_time - waveform_start\n","prediction = 60\n","\n","print(\"Wavefrom shape:\",np.shape(tr))\n","print(\"PKIKP onset: ak135 prediction: %.2f s; Hand picking: %.2f s\"%(prediction,onset))"]},{"cell_type":"markdown","metadata":{"id":"3i334AgBwSs9"},"source":["Pre-process the waveform. A default 50-s length waveform segment around the ak135 prediction is cut as the input of the automatic picker."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2025-03-12T03:42:45.526592Z","start_time":"2025-03-12T03:42:45.497655Z"},"id":"pWHn40DUwSs9"},"outputs":[],"source":["sampling_rate = 40\n","len_input = 50\n","freq_filter = [0.5,2]\n","tr_cut = pre_process(tr, sampling_rate, len_input, freq_filter[0], freq_filter[1])"]},{"cell_type":"markdown","metadata":{"id":"YtmcCfhNwSs9"},"source":["Pick the PKIKP onset on the processed waveform by calling the Picker function. A 20-s length window is shifting along the input waveform, and the network model returns an instantaneous pick for each step. The pick with the highest quality is chosen as the optimal one."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2025-03-12T03:42:48.199571Z","start_time":"2025-03-12T03:42:47.991755Z"},"id":"ld3o4IFWwSs9"},"outputs":[],"source":["auto_pick, quality = picker(tr_cut, model_raw, sampling_rate, return_optimal = True)\n","\n","print(\"Auto picked PKIKP onset: %.2f s picking quality: %.2f\"%(auto_pick[0], quality[0]))\n","onset_in_window = onset - prediction + len_input / 2\n","print(\"Manual pick on the waveform: %.2f s\"%onset_in_window)"]},{"cell_type":"markdown","metadata":{"id":"1jyOh3p1wSs-"},"source":["### Result plotting"]},{"cell_type":"markdown","metadata":{"id":"rwbJOHy_wSs-"},"source":["We can acquire all picks with quality and get a quality plot."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2025-03-12T03:42:59.751022Z","start_time":"2025-03-12T03:42:59.400253Z"},"id":"UWCZVdNlwSs-"},"outputs":[],"source":["auto_pick_plot(tr_cut, model_raw, \"PKP_NE22.YP.BHZ.SAC.jpg\")"]},{"cell_type":"markdown","metadata":{"id":"n2k-_Ej0wSs-"},"source":["An animation displaying the dynamic picking process is saved."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2025-03-12T03:43:16.185087Z","start_time":"2025-03-12T03:43:01.366786Z"},"id":"bPxYzeIOwSs-"},"outputs":[],"source":["picking_animation(tr_cut, model_raw, save_name=\"Animation.mp4\")"]},{"cell_type":"markdown","metadata":{"id":"mnZVqhTbeMUZ"},"source":["---\n","## Challenge\n","\n","Would you mind to try the trained network on more real waveform data? Copy the code below to and replace `<CHANGE ME>` with necessary code for for reald processing. You can start with the code here:\n","\n","    Code example"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"COpXtwFV-EQx"},"outputs":[],"source":["## Enter your code here"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"yiSUUxiXeKkA"},"outputs":[],"source":["#@title Click here for solution\n","\n","# Load training data\n","waveforms_2, labels_2, names_2 = load_train_data(loading_num=15000)\n","\n","# Create a new raw model, which should have the exact architecture as the first one\n","model_2 = model_raw = create_CNN_picker(npts = waveform_len*sampling_rate)\n","\n","# Split data for training\n","## Stack three training sets\n","x_2 = np.vstack(waveforms_2)\n","y_2 = np.vstack(labels_2)\n","\n","## data is shuffled before splitting\n","x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(x_2, y_2, test_size = 0.1, shuffle = True, random_state = 101)\n","\n","## Train\n","hist_2 = trainer(x_train_2, y_train_2,\n","        model_2,\n","        epochs = 30,\n","        validation_split = 0.2,\n","        batch_size = 32,\n","        early_stop = True,\n","        verbose_training = 1,\n","        shuffle = True, # Shuffle the training data before each epoch\n","        plot_hist = False)\n","\n","## Predict on test data\n","model_2.predict(x_test_2)\n","\n","y_out_2 = model_raw.predict(x_test_2)\n","fig, ax = plt.subplots()\n","ax.set_aspect('equal')\n","ax.scatter(y_test_2, y_out_2)\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/tsonpham/ObsSeis-VNU/blob/master/Day5/D5_Lab.ipynb","timestamp":1742259711029}]},"kernelspec":{"display_name":"emcee","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":0}