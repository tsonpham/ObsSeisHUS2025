{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyI66TSUfNbJ"
   },
   "source": [
    "# Triangulation of M5.2 Kon Tum 28/07/2024 earthquake\n",
    "\n",
    "[![Open In Colab](https://img.shields.io/badge/open%20in-Colab-b5e2fa?logo=googlecolab&style=flat-square&color=ffd670)](https://colab.research.google.com/github/tsonpham/ObsSeisHUS2025/blob/master/Day2/D2_Prac.ipynb)\n",
    "\n",
    "Prepared by Thanh-Son Pham (thanhson.pham@anu.edu.au), April 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zft3XEcPfNbM"
   },
   "source": [
    "---\n",
    "## What we do in this note book\n",
    "\n",
    "Here we learn one of the most fundamental skill in observational seismology, triangulating earthquakes using P- and S-wave arrivals.\n",
    "\n",
    "Lets start with the fact-sheet and answer some questions,\n",
    "- https://www.iris.edu/hq/inclass/fact-sheet/how_are_earthquakes_located\n",
    "\n",
    "More information can be in the official websites,\n",
    "- https://www.iris.edu/hq/inclass/lesson/locating_an_earthquake_with_recent_seismic_data\n",
    "- https://www.iris.edu/hq/inclass/software-web-app/earthquake_triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5968,
     "status": "ok",
     "timestamp": 1745275953892,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "lFfgRK1_fNbM",
    "outputId": "b1e97d17-39ef-4611-e2f1-ed67aea26b76"
   },
   "outputs": [],
   "source": [
    "# set up colab environment - uncomment the next line if running in colab\n",
    "\n",
    "# !pip install basemap obspy basemap-data-hires cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1745275953926,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "gN1ZUic2fNbN"
   },
   "outputs": [],
   "source": [
    "#@title Run to set up retina display\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams[\"savefig.dpi\"] = 100\n",
    "rcParams[\"figure.dpi\"] = 100\n",
    "rcParams[\"font.size\"] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CGFQuBGfNbO"
   },
   "source": [
    "---\n",
    "## Data preparation\n",
    "Lets start by fetching the metadata of the M5.2 Kon Tum 28/07/2024 earthquake from the ISC catalog.\n",
    "\n",
    "Because the event is large enought, the event's location and time are reported by several earthquake data acencies including the Intitutue of Geophysics, Vietnam Academy of Science and Technology. Smaller earthquakes in the region are only processed and reported by the VAST IGP (see Module 1's in-class exercise).\n",
    "\n",
    "The ISC catalog are often reported by regional agencies and release the comprehensive catalog of global seismicity to the public. The ISC reviewed signficant events using their protocols and publish REVIEWED solutions often about with 2 years delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2532,
     "status": "ok",
     "timestamp": 1745275956460,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "2JvKDX8MfNbO",
    "outputId": "02cca8d1-c5e4-4980-8bac-6ec1fb6013ee"
   },
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "\n",
    "# Initialize the client for ISC\n",
    "isc = Client(\"ISC\")\n",
    "\n",
    "# Request event information\n",
    "event = isc.get_events(eventid=\"641665444\")[0]\n",
    "\n",
    "# Print the event information\n",
    "print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AUkSqq2fNbP"
   },
   "source": [
    "We use the origin time to download waveform data to demonstrate the concepts of earthquake triangulation. Data are downloaded using the [`obspy mass_downloader`](https://docs.obspy.org/packages/autogen/obspy.clients.fdsn.mass_downloader.html) tool. This tool is very helpful to explore the availability of seismic waveforms in a unfamiliar region without much local knowledge of the local seismic infrastructure. We will learn more about accessing seismic data later in this lecture series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12929,
     "status": "ok",
     "timestamp": 1745275969388,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "67Bfv0TifNbP",
    "outputId": "175be72e-be24-41b4-8a19-f9927fef104d"
   },
   "outputs": [],
   "source": [
    "## download all available data using mass_downloader\n",
    "from obspy.clients.fdsn.mass_downloader import CircularDomain, Restrictions, MassDownloader\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the origin time, latitude, and longitude of the Kon Tum event\n",
    "origin_time = event.preferred_origin().time\n",
    "origin_lat = event.preferred_origin().latitude\n",
    "origin_lon = event.preferred_origin().longitude\n",
    "\n",
    "# Circular domain around the epicenter. This will download all data between\n",
    "# 70 and 90 degrees distance from the epicenter. This module also offers\n",
    "# rectangular and global domains. More complex domains can be defined by\n",
    "# inheriting from the Domain class.\n",
    "domain = CircularDomain(origin_lat, origin_lon, minradius=0.0, maxradius=15.0)\n",
    "\n",
    "restrictions = Restrictions(\n",
    "    # Get data from 5 minutes before the event to one hour after the\n",
    "    # event. This defines the temporal bounds of the waveform data.\n",
    "    starttime=origin_time - 1 * 60,\n",
    "    endtime=origin_time + 10 * 60,\n",
    "    # You might not want to deal with gaps in the data. If this setting is\n",
    "    # True, any trace with a gap/overlap will be discarded.\n",
    "    reject_channels_with_gaps=True,\n",
    "    # And you might only want waveforms that have data for at least 95 % of\n",
    "    # the requested time span. Any trace that is shorter than 95 % of the\n",
    "    # desired total duration will be discarded.\n",
    "    minimum_length=0.95,\n",
    "    # No two stations should be closer than 10 km to each other. This is\n",
    "    # useful to for example filter out stations that are part of different\n",
    "    # networks but at the same physical station. Settings this option to\n",
    "    # zero or None will disable that filtering.\n",
    "    minimum_interstation_distance_in_m=150E3,\n",
    "    # Only HH or BH channels. If a station has HH channels, those will be\n",
    "    # downloaded, otherwise the BH. Nothing will be downloaded if it has\n",
    "    # neither. You can add more/less patterns if you like.\n",
    "    channel_priorities=[\"BH[ZNE12XY]\", \"HH[ZNE]\"],\n",
    "    # Location codes are arbitrary and there is no rule as to which\n",
    "    # location is best. Same logic as for the previous setting.\n",
    "    location_priorities=[\"\", \"00\", \"10\"])\n",
    "\n",
    "# No specified providers will result in all known ones being queried.\n",
    "mdl = MassDownloader(providers=['IRIS'])\n",
    "# The data will be downloaded to the ``./waveforms/`` and ``./stations/``\n",
    "# folders with automatically chosen file names.\n",
    "if not (Path(\"waveforms\").exists() and Path(\"stations\").exists()):\n",
    "    mdl.download(domain, restrictions, mseed_storage=\"waveforms\",\n",
    "                stationxml_storage=\"stations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUAJmHr8fNbQ"
   },
   "source": [
    "In practice, we do not know the existence of the seismic event in advance, the event might be reported by locals or detected by an earthquake detection method. After detection, refining the event location is the second step to build an earthquake catalog.\n",
    "\n",
    "Now, let's read the station metadata and plot their local map using the built-in plotting routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "executionInfo": {
     "elapsed": 23781,
     "status": "ok",
     "timestamp": 1745275993170,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "gH-cVBu7fNbQ",
    "outputId": "cbb43a8c-b8b1-4364-e086-ca928c1fcfb4"
   },
   "outputs": [],
   "source": [
    "# read station metadata\n",
    "from obspy import read_inventory, Inventory\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inv = Inventory()\n",
    "for file in Path(\"stations\").glob(\"*.xml\"):\n",
    "    inv += read_inventory(str(file))\n",
    "\n",
    "inv.plot(projection='local', show=True, size=30, resolution='i')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6we5pnbEfNbQ"
   },
   "source": [
    "Here we practise the mapping skill learned in Day 1 to plot the station map at the regional scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 667,
     "status": "ok",
     "timestamp": 1745275993840,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "xmpLnsJkfNbQ",
    "outputId": "c1be112b-4e7b-4ef9-f474-8cc81828b509"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import numpy as np\n",
    "\n",
    "# create a new figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "# initialize the basemap, specifing the projection, the gegraphic buondary, and resolution\n",
    "# the initialzed map instance is attached to the axis ax\n",
    "m = Basemap(projection='merc',ax=ax, llcrnrlat=0, urcrnrlat=26, llcrnrlon=94, urcrnrlon=122, resolution='l')\n",
    "# draw coastlines\n",
    "m.drawcoastlines(linewidth=0.75)\n",
    "# draw country boundaries\n",
    "m.drawcountries(linewidth=0.75)\n",
    "# draw parallels and meridians\n",
    "m.drawparallels(range(0, 25, 5), labels=[1,0,0,0], linewidth=0.3, color='gray', dashes=(5, 3))\n",
    "m.drawmeridians(range(90, 125, 5), labels=[0,0,0,1], linewidth=0.3, color='gray', dashes=(5, 3))\n",
    "\n",
    "# plot the epicenter\n",
    "m.plot(origin_lon, origin_lat, 'r*', markersize=12, label='Epicenter', latlon=True)\n",
    "\n",
    "# plot the station locations\n",
    "for network in inv:\n",
    "    for station in network:\n",
    "        lon = station.longitude\n",
    "        lat = station.latitude\n",
    "        m.plot(lon, lat, '^', c='magenta', markersize=8, latlon=True)\n",
    "\n",
    "# plot distance contours to the epicenter\n",
    "from obspy.geodetics import locations2degrees\n",
    "x = np.linspace(m.xmin, m.xmax, 300)\n",
    "y = np.linspace(m.ymin, m.ymax, 300)\n",
    "mlon, mlat = m(*np.meshgrid(x, y), inverse=True)\n",
    "dist = locations2degrees(origin_lat, origin_lon, mlat, mlon)\n",
    "mapple = m.contour(mlon, mlat, dist, levels=range(0, 19, 3), latlon=True, colors='k', linewidths=0.75)\n",
    "plt.clabel(mapple, inline=True, fmt='%1.0f$^\\circ$', colors='black', use_clabeltext=True)\n",
    "\n",
    "# # add a colorbar\n",
    "# plt.colorbar(mapple, label='Distance to epicenter [Â°]')\n",
    "\n",
    "# show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_I9y7mbfNbR"
   },
   "source": [
    "---\n",
    "## Waveform processing and section plot\n",
    "\n",
    "Lets read in waveform data as `obspy Stream` and high-pass filter the raw waveforms. In seismology, [Butterworth](https://en.wikipedia.org/wiki/Butterworth_filter) filter are widely used, often by default, in many seismological applications.\n",
    "\n",
    "Please see much greater details on [filtering](https://seismo-live.github.io/html/Signal%20Processing/filter_basics_solution_wrapper.html) from this notebook. Note that we set `zerophase=False` here when interesting in the arrival time. After reading the cited notebook on seismogram filtering, could you explain why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30641,
     "status": "ok",
     "timestamp": 1745276024483,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "ZnK4CjFMfNbR"
   },
   "outputs": [],
   "source": [
    "from obspy import read, Stream\n",
    "\n",
    "# read the waveform data from the downloaded files\n",
    "dstream = Stream()\n",
    "for file in Path(\"waveforms\").glob(\"*.mseed\"):\n",
    "    dstream += read(str(file))\n",
    "\n",
    "# # select only the Z component for each station\n",
    "# dstream = dstream.select(component='Z')\n",
    "\n",
    "# remove instrument response\n",
    "dstream.remove_response(inventory=inv, output='VEL')\n",
    "\n",
    "# trim the data to the time window of interest\n",
    "dstream.filter('highpass', freq=0.1, corners=2, zerophase=False)\n",
    "dstream = dstream.trim(starttime=origin_time, endtime=origin_time + 600)\n",
    "# append the distance in meters to the trace stats\n",
    "for tr in dstream:\n",
    "    tmp = inv.select(station=tr.stats.station, network=tr.stats.network)\n",
    "    stla = tmp[0][0].latitude\n",
    "    stlo = tmp[0][0].longitude\n",
    "    tr.data /= np.max(np.abs(tr.data))\n",
    "    tr.stats.update({'distance':locations2degrees(origin_lat, origin_lon, stla, stlo)*111.1195e3,\n",
    "                     'stla':stla, 'stlo':stlo})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Xv5hipbfNbR"
   },
   "source": [
    "Real seismograms often contain with electrical glitches, gaps, or abnormal recordings. One often needs to be mindful about data quality control when dealing with real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "executionInfo": {
     "elapsed": 1652,
     "status": "ok",
     "timestamp": 1745276026132,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "hzvZPK4EfNbR",
    "outputId": "dba3d1fc-4cc4-4d10-f82b-1d72643a0b13"
   },
   "outputs": [],
   "source": [
    "from obspy.taup import TauPyModel\n",
    "taup_model = TauPyModel(model=\"ak135\")\n",
    "\n",
    "## plot stream waveform data using the build-in plotting function\n",
    "fig = plt.figure()\n",
    "dstream.select(component='Z').plot(type='section', orientation='horizontal', norm_method='stream', fig=fig)\n",
    "\n",
    "## annotate the plot with station names\n",
    "ax = fig.gca()\n",
    "ax.set_title('M5.2 Kon Tum 28/07/2024 earthquake')\n",
    "for tr in dstream.select(component='Z'):\n",
    "    dist_in_km = tr.stats.distance / 1e3\n",
    "    ax.text(20, dist_in_km, tr.stats.station, color='r')\n",
    "    # plot the predicted arrival time of P-wave\n",
    "    arvs = taup_model.get_travel_times(0, dist_in_km/111.1195, phase_list=['P'])\n",
    "    ax.plot(arvs[0].time, dist_in_km, '|r', markersize=10, label='P arrival')\n",
    "    # save arrival to trace stats\n",
    "    tr.stats.p_arrival = arvs[0].time\n",
    "    # plot the predicted arrival time of S-wave\n",
    "    arvs = taup_model.get_travel_times(0, dist_in_km/111.1195, phase_list=['S'])\n",
    "    ax.plot(arvs[0].time, dist_in_km, '|b', markersize=10, label='S arrival')\n",
    "    # save arrival to trace stats\n",
    "    tr.stats.s_arrival = arvs[0].time\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_JJlPEVfNbS"
   },
   "source": [
    "Here, we develop a simple procedure to get rid of waveforms of low signal-to-noise ratio. The noise segment is empirically defined as the first 60 seconds of the seismograms. The signal segment is defined as the 60-second segment from the predicted P-wave arrivals. The signal-to-noise ratio (SNR) is ratio between the standard devication of the signal to the noise segments. SNR below 2.0 is empirically considered to be noisy and rejected from further consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "executionInfo": {
     "elapsed": 807,
     "status": "ok",
     "timestamp": 1745276026941,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "7CAgNgkQfNbS",
    "outputId": "05d03e78-d1bc-43ff-c51b-70afc37b92bc"
   },
   "outputs": [],
   "source": [
    "## Calculate individual traces' signal to noise ratio\n",
    "for tr in dstream.select(component='Z'):\n",
    "    tvec = tr.times()\n",
    "    # calculate the noise level\n",
    "    noise = np.std(tr.data[tvec < 60])\n",
    "    # calculate the signal level\n",
    "    signal = np.std(tr.data[np.logical_and(tr.stats.p_arrival<=tvec, tvec<tr.stats.s_arrival+60)])\n",
    "    # calculate the SNR\n",
    "    tr.stats.snr = signal / noise\n",
    "dstream_good = Stream([tr for tr in dstream.select(component='Z') if tr.stats.snr > 2])\n",
    "\n",
    "## plot stream waveform data using the build-in plotting function\n",
    "fig = plt.figure()\n",
    "dstream_good.plot(type='section', orientation='horizontal', norm_method='stream', fig=fig)\n",
    "\n",
    "## annotate the plot with station names\n",
    "ax = fig.gca()\n",
    "ax.set_title('M5.2 Kon Tum 28/07/2024 earthquake')\n",
    "for tr in dstream_good:\n",
    "    dist_in_km = tr.stats.distance / 1e3\n",
    "    ax.text(20, dist_in_km, tr.stats.station, color='r')\n",
    "    # plot the predicted arrival time of P-wave\n",
    "    arvs = taup_model.get_travel_times(0, dist_in_km/111.1195, phase_list=['P'])\n",
    "    ax.plot(arvs[0].time, dist_in_km, '|r', markersize=10, label='P arrival')\n",
    "    # save arrival to trace stats\n",
    "    tr.stats.p_arrival = arvs[0].time\n",
    "    # plot the predicted arrival time of S-wave\n",
    "    arvs = taup_model.get_travel_times(0, dist_in_km/111.1195, phase_list=['S'])\n",
    "    ax.plot(arvs[0].time, dist_in_km, '|b', markersize=10, label='S arrival')\n",
    "    # save arrival to trace stats\n",
    "    tr.stats.s_arrival = arvs[0].time\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gti2MD2JfNbS"
   },
   "source": [
    "---\n",
    "## Arrival time picking\n",
    "\n",
    "Now, we learn how to infer the source location by observing the seismic waveforms. The P and S wave arrival time were manually picked subjected to temopral resolution errors. The travel time picks will later be used to triangulate the event location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1745276026945,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "taC3wPLmfNbS"
   },
   "outputs": [],
   "source": [
    "#@title Function to plot the waveforms for a given station with arrival times\n",
    "def plot_waveforms(station):\n",
    "    import matplotlib.dates as mdates\n",
    "    fig = plt.figure()\n",
    "    ## select the trace for the given station and plot them\n",
    "    st = dstream.select(station=station)\n",
    "    st.plot(fig=fig, starttime=origin_time, endtime=origin_time + 300)\n",
    "    ## mark the P and S arrival times\n",
    "    for ax in fig.axes:\n",
    "        # P wave arrival\n",
    "        p_arr = pick_data[station]['p_arr']\n",
    "        ax.axvline(p_arr, color='r', linestyle='--', linewidth=1)\n",
    "        ax.text(p_arr, .3, 'P', color='r', fontsize=12)\n",
    "        # S wave arrival\n",
    "        s_arr = pick_data[station]['s_arr']\n",
    "        ax.axvline(s_arr, color='b', linestyle='--', linewidth=1)\n",
    "        ax.text(s_arr, .3, 'S', color='b', fontsize=12)\n",
    "    fig.axes[0].xaxis.set_minor_locator(mdates.SecondLocator(interval=10))\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "executionInfo": {
     "elapsed": 1434,
     "status": "ok",
     "timestamp": 1745276028381,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "ExdfbQgBfNbS",
    "outputId": "a31e2bb1-52d5-423d-c7e5-40c12a57308c"
   },
   "outputs": [],
   "source": [
    "#@title Manually pick the P and S wave arrival times at station VIVO.\n",
    "from datetime import datetime\n",
    "pick_data = {}\n",
    "pick_data['QIZ'] = dict(\n",
    "    p_arr = datetime(2024,7,28,4,36,20),\n",
    "    s_arr = datetime(2024,7,28,4,37,9))\n",
    "plot_waveforms('QIZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "executionInfo": {
     "elapsed": 1579,
     "status": "ok",
     "timestamp": 1745276029972,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "85GtzV_GfNbT",
    "outputId": "94201add-94b7-4dde-8bdf-a7f9f6a0754d"
   },
   "outputs": [],
   "source": [
    "#@title Manually pick the P and S wave arrival times at station VIVO\n",
    "pick_data['VIVO'] = dict(\n",
    "    p_arr = datetime(2024,7,28,4,36,37),\n",
    "    s_arr = datetime(2024,7,28,4,37,35))\n",
    "plot_waveforms('VIVO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "executionInfo": {
     "elapsed": 2121,
     "status": "ok",
     "timestamp": 1745276032095,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "_m2LvsC2fNbT",
    "outputId": "230171a7-f84b-4f6d-ce74-eb5d15f4e7c7"
   },
   "outputs": [],
   "source": [
    "#@title Manually pick the P and S wave arrival times at station PBKT\n",
    "pick_data['PBKT'] = dict(\n",
    "    p_arr = datetime(2024,7,28,4,37,0),\n",
    "    s_arr = datetime(2024,7,28,4,38,20))\n",
    "plot_waveforms('PBKT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi4nEaQvfNbT"
   },
   "source": [
    "---\n",
    "## P- and S-wave travel time curves\n",
    "\n",
    "Construct the S- to P- differential travel time curves and convert the observed difference to distance (in kms) for each station in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1731,
     "status": "ok",
     "timestamp": 1745276033828,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "I6PT4mZcfNbT"
   },
   "outputs": [],
   "source": [
    "## build the travel time curve for the P and S waves\n",
    "dist = np.arange(0, 1800, 50)\n",
    "time_p = np.zeros_like(dist)\n",
    "time_s = np.zeros_like(dist)\n",
    "for i, d in enumerate(dist):\n",
    "    arvs = taup_model.get_travel_times(source_depth_in_km=0, distance_in_degree = d/111.1195, phase_list=['P'])\n",
    "    time_p[i] = arvs[0].time\n",
    "    arvs = taup_model.get_travel_times(source_depth_in_km=0, distance_in_degree = d/111.1195, phase_list=['S'])\n",
    "    time_s[i] = arvs[0].time\n",
    "\n",
    "for station in pick_data.keys():\n",
    "    ## time difference to distance conversion\n",
    "    tdiff = UTCDateTime(pick_data[station]['s_arr']) - UTCDateTime(pick_data[station]['p_arr'])\n",
    "    pick_data[station]['dist'] = np.interp(tdiff, time_s - time_p, dist)\n",
    "    ## update the pick_data dictionary with the station coordinates\n",
    "    pick_data[station]['lon'] = inv.select(station=station)[0][0].longitude\n",
    "    pick_data[station]['lat'] = inv.select(station=station)[0][0].latitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGLVMX3cfNbT"
   },
   "source": [
    "---\n",
    "## Earthquake triangulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "witzel1ofNbT"
   },
   "source": [
    "At each station, we draw the circle with radius equal to the estimated distance. The intersection of three circles roughly determine the earthquake hypocenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 3124,
     "status": "ok",
     "timestamp": 1745276036955,
     "user": {
      "displayName": "Thanh Son Pham",
      "userId": "17941529104681711853"
     },
     "user_tz": -420
    },
    "id": "csSqrp-pfNbT",
    "outputId": "4e2d8301-948d-450d-f632-874595153e34"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# create a new figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "# initialize the basemap, specifing the projection, the gegraphic buondary, and resolution\n",
    "# the initialzed map instance is attached to the axis ax\n",
    "m = Basemap(projection='merc',ax=ax, llcrnrlat=0, urcrnrlat=26,\n",
    "            llcrnrlon=94, urcrnrlon=122, resolution='i')\n",
    "# draw coastlines\n",
    "m.drawcoastlines(linewidth=0.75)\n",
    "# draw country boundaries\n",
    "m.drawcountries(linewidth=0.75)\n",
    "# draw parallels and meridians\n",
    "m.drawparallels(range(0, 25, 5), labels=[1,0,0,0], linewidth=0.3, color='gray', dashes=(5, 3))\n",
    "m.drawmeridians(range(90, 125, 5), labels=[0,0,0,1], linewidth=0.3, color='gray', dashes=(5, 3))\n",
    "\n",
    "# plot the station locations\n",
    "for key, val in pick_data.items():\n",
    "    m.plot(val['lon'], val['lat'], '^', c='magenta', markersize=8, latlon=True)\n",
    "    m.tissot(val['lon'], val['lat'], val['dist']/111.1195, 100, facecolor='none', edgecolor='k', linewidth=0.5)\n",
    "    x, y = m(val['lon'], val['lat'])\n",
    "    ax.text(x, y+4e4, key, fontsize='small', color='r', ha='center')\n",
    "    pick_data[key].update({'x': x, 'y': y})\n",
    "\n",
    "# plot the epicenter\n",
    "m.plot(origin_lon, origin_lat, '*', markersize=12, label='Epicenter', latlon=True, c='none', mec='r')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezd7_GDhfNbU"
   },
   "source": [
    "Here we use our customized script to triangulate the Kon Tum earthquake hypocenter. This IRIS [webapp](https://www.iris.edu/hq/inclass/software-web-app/earthquake_triangulation) has similar functionality. You need to provide the station coordinates, and estimated distances (from S- to P-travel time differences).\n",
    "\n",
    "Why not you try it out if you have finished early?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QG0g9mr0fNbU"
   },
   "source": [
    "---\n",
    "## Remarks\n",
    "\n",
    "- Earthquake triangulation is one the classical task in seismology, which was done with paper and pen over printed seismograms and maps by early seismologist.\n",
    "\n",
    "- This exercise hopefully give you some initial senses about dealing with real seismic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQv0pAx2fNbU"
   },
   "source": [
    "---\n",
    "## Bonus project\n",
    "\n",
    "Hello, thank you for being interested in the bonus project. Although everyone is encouraged to complete bonus projects, undergrad students will be considered for bonus points to their final exams. Best of luck!\n",
    "\n",
    "*In this project, you are asked to modify the cells to pick arrivals time of at least three stations recording the M7.7 Myanmar 28/03/2025 earthquake, [643071319](https://isc.ac.uk/cgi-bin/web-db-run?event_id=643071319&out_format=ISF2&request=COMPREHENSIVE), and triangulate it either with the customized or IRIS webapp tool.*\n",
    "\n",
    "If you submit a working code towards completing the task, you will get 50% points. If the code produces correct outcome, you will get 75%. The minimal two-paragraphs on the motivation and additional thoughts will get you to 100%.\n",
    "\n",
    "Please submit this jupyter notebook to the following form: https://forms.gle/L5QLLYMEnm277bTMA."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "emcee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
